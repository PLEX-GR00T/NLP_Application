# NLP

List of Main Projects.
- **Project 1**: Create your own dataset for Q&A application
- **Project 2**: Use SQUAD2.0 dataset and create TFIDF and Word2Vecor.

# Project 1: 
### **Task 1**: Create the dataset.
- We created our own dataset of 1000+ questions annotating 200 paragraphs from the wikipedia.
- Just to make the process easy we used Geography as our theme to collect the data.
- We annotated our data using Haystack web based application.

### **Task 2**: Know more about your own created dataset.
- Type of Question asked.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/que_types.png)

- Lengthe of the question asked.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/que_len.png)

- Paragraph Length.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/paragraph_len.png)

- Length of the answers.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/answer_text_len.png)

- Min Max Length of the answers annotated.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/min_max_length.png) 

### **Task 3**: Fine-tune your won model depending on your dataset.
- Tried differen model and its comparison.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/All_model_Accuracy_compare.png)

- Benchmark of trained models on same question asked to all models.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/all_Question_Models_Accuracy_compare.png)


### **Task 4**: Create a streamline application for your Q&A use for Schools and University.
- We also created the streamline application for the universities and schools that looked just like below.
- This application used the model trained on our customized and finetuned model.
- This application was based on the Factual Question Answer.
- We used this [github](https://github.com/mihail911/question-answering-with-streamlit) to cread the replica for our application.

![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/qa_streamlit.gif)

