# NLP

List of Main Projects.
- **Project 1**: Create your own dataset for Q&A application
- **Project 2**: Use SQUAD2.0 dataset and create TFIDF and Word2Vecor.

# Project 1: 
### **Task 1**: Create the dataset.
- We created our own dataset of 1000+ questions annotating 200 paragraphs from the wikipedia.
- Just to make the process easy we used Geography as our theme to collect the data.
- We annotated our data using Haystack web based application.

### **Task 2**: Know more about your own created dataset.
- Type of Question asked.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/que_types.png)

- Lengthe of the question asked.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/que_len.png)

- Paragraph Length.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/paragraph_len.png)

- Length of the answers.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/answer_text_len.png)

- Min Max Length of the answers annotated.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/min_max_length.png) 

### **Task 3**: Fine-tune your won model depending on your dataset.
- Tried differen model and its comparison.
![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/All_model_Accuracy_compare.png)

- Benchmark of trained models on same question asked to all models.
-![image](https://github.com/PLEX-GR00T/NLP/blob/main/Outputs/all_Question_Models_Accuracy_compare.png)


### **Task 4**: Create a streamline application for your Q&A use for Schools and University.

## Task 1:
- 

